<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="NO response">
  
  
    <meta name="description" content="what you will be,the world will be">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    神经网络参数的反向传播算法 |
    
    种花家</title>
  
    <link rel="shortcut icon" href="/images/rabbit.png">
  
  <link rel="stylesheet" href="../../../../css/style.css">
  <link rel="stylesheet" href="../../../../css/technology.css">
  
    <link rel="stylesheet" href="../../../../fancybox/jquery.fancybox.min.css">
  
  <script src="../../../../js/pace.min.js"></script>
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <section class="outer">
  <article id="post-神经网络参数的反向传播算法" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      神经网络参数的反向传播算法
    </h1>
  

      </header>
    

    
      <div class="article-meta">
        <a href class="article-date">
  <time datetime="2019-07-29T01:13:00.000Z" itemprop="datePublished">2019-07-29</time>
</a>
        
  <div class="article-category">
    <a class="article-category-link" href="../../../../categories/机器学习/">机器学习</a>
  </div>

      </div>
    

    <div class="article-entry" itemprop="articleBody">
      

      

      
        <h3 id="学习地址"><a href="#学习地址" class="headerlink" title="学习地址"></a><center><a href="https://study.163.com/course/courseLearn.htm?courseId=1004570029#/learn/video?lessonId=1051775907&amp;courseId=1004570029" target="_blank" rel="noopener">学习地址</a></center></h3><h4 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h4><p>在之前的前向传播算法中并没于介绍神经网络是如何训练参数的，而作业也是直接给出了&theta;<sup>1</sup>和&theta;<sup>2</sup>。那么这里介绍神经网络的代价函数就是这个目的。<br>定义：<br>      L：神经网络总层数<br>      s<sub>l</sub>：第l层的单元数，不包括bias unit在内</p>
<p>二分类问题输出只有0和1，但多元分类问题输出可能是个向量也可能是个矩阵，这里就先用下图为例，输出是一个4维<strong>向量</strong><br><img src="https://i.loli.net/2019/07/29/5d3e4a733a89d29057.png" alt="2019-07-29 09-21-12 的屏幕截图.png"></p>
<p>神经网络代价函数：<br><img src="https://i.loli.net/2019/07/29/5d3e4fd74dd0e36818.png" alt="2019-07-29 09-45-49 的屏幕截图.png"><br>关于神经网络代价函数解释：</p>
<ul>
<li>在神经网络问题中，应用的是多元分类问题，输出一个多维向量，那么假设函数h<sub>&theta;</sub>(X)&isin;R<sup>K</sup>。(h<sub>&theta;</sub>(X))<sub>i</sub>表示第i个输出的假设函数。我们在多元分类与前向传播算法中就是根据这个值确定属于哪一分类的。</li>
<li>y<sub>k</sub><sup>(i)</sup>表示第i的样本的输出，也是一个binary vector如上图。</li>
<li>最后一项是正则化项，最初(逻辑回归)在接触正则化项的时候只是为了防止过拟合现象，这里本质也还是逻辑回归。有时候正则化项也叫惩罚项，老板是这样叫的。</li>
<li>为什么正则化项是三层循环呢？用上面的神经网络图来解释，就相当于把每条线上的权值求平方和而已，一般不惩罚第0项&theta;，但其实惩罚也没多大差别，只不过不惩罚&theta;<sub>0</sub>更常用些。</li>
</ul>
<h4 id="反向传播算法-Backpropagation"><a href="#反向传播算法-Backpropagation" class="headerlink" title="反向传播算法 Backpropagation"></a><font color="red">反向传播算法 Backpropagation</font></h4><p>视频地址：<a href="https://study.163.com/course/courseLearn.htm?courseId=1004570029#/learn/video?lessonId=1051773834&amp;courseId=1004570029" target="_blank" rel="noopener">反向传播算法</a> ，比较复杂<br>目的：最小化代价函数。<br>TODO：代码实现计算代价函数J(&theta;)，推导并实现出偏导项<br><img src="https://i.loli.net/2019/07/29/5d3e56d1ba02418982.png" alt="2019-07-29 10-15-33 的屏幕截图.png"><br>梯度计算方法如下：这里参照前向传播作业可以直接用矩阵实现<br>h<sub>&theta;</sub>(x)叫<a href="https://www.cnblogs.com/missidiot/p/9378079.html" target="_blank" rel="noopener">激活值</a><br><img src="https://i.loli.net/2019/07/29/5d3e57ba630bb65590.png" alt="2019-07-29 10-17-55 的屏幕截图.png"></p>
<p>反向传播算法概念与计算方法:<br><img src="https://i.loli.net/2019/07/29/5d3e62512d6d194144.png" alt="2019-07-29 11-04-33 的屏幕截图.png"><br>解释：</p>
<ul>
<li>&delta;<sub>j</sub><sup style="margin-left:-5px">(l)</sup>表示第i层第j个节点误差，即a<sub>j</sub><sup style="margin-left:-5px">(i)</sup>-y<sub>j</sub>。  </li>
<li>知道了最后一层的误差就可以推出前面所有层的误差，如上计算公式</li>
<li>g&prime;(z<sup>(3)</sup>)表示导数项，z=&theta;<sup>T</sup>X；h<sub>&theta;</sub>(X)=g(z)=a=sigmoid(z)=1/(1+e<sup>-z</sup>)。而由微积分对z求导可以推出g&prime;(z<sup>(3)</sup>)=a<sup>(3)</sup>  (1-a<sup>(3)</sup>)，其余同理。这里<code>.*</code>表示普通元素对应相乘。</li>
</ul>
<p>计算方法：<br><img src="https://i.loli.net/2019/07/29/5d3e693128cbf17961.png" alt="2019-07-29 11-29-06 的屏幕截图.png"></p>
<h4 id="理解反向传播算法"><a href="#理解反向传播算法" class="headerlink" title="理解反向传播算法"></a>理解反向传播算法</h4><p>Cost(i)表示了神经网络预测样本值的准确程度，即网络的输出值与实际y值的偏差程度<br>反向传播算法实际上是在计算&delta;<sub>j</sub><sup style="margin-left:-5px">(l)</sup>，而&delta;<sub>j</sub><sup style="margin-left:-5px">(l)</sup>恰恰等于cost(i)关于z<sub>j</sub><sup style="margin-left:-5px">(l)</sup>的偏导数，其中对于只有一个样本输入来说，cost(i)已经给出如下：<br><img src="https://i.loli.net/2019/07/29/5d3e94b32da1941274.png" alt="2019-07-29 14-39-38 的屏幕截图.png"><br><img src="https://i.loli.net/2019/07/29/5d3ea10938ff424869.png" alt="2019-07-29 15-32-15 的屏幕截图.png"></p>
<h4 id="展开参数"><a href="#展开参数" class="headerlink" title="展开参数"></a>展开参数</h4><p>为了计算方便将所有参数矩阵展开成向量形式，传入函数进行计算<br><img src="https://i.loli.net/2019/07/29/5d3ea6c63625485539.png" alt="2019-07-29 15-56-23 的屏幕截图.png"><br><img src="https://i.loli.net/2019/07/29/5d3ea6c62261433560.png" alt="2019-07-29 15-56-44 的屏幕截图.png"></p>
<h4 id="梯度检测"><a href="#梯度检测" class="headerlink" title="梯度检测"></a>梯度检测</h4><p>为了保证正确实现了梯度，而且每次下降都是正确的，不至于最终得出结果和实际误差存在量级别的差异。<br>梯度检测是计算量非常大，在验证了反向传播算法所计算的梯度和梯度检测相差不多时就可以关闭梯度检测再直接用反向传播算法训练分类器。<br><img src="https://i.loli.net/2019/07/29/5d3eaa259ce1e67757.png" alt="2019-07-29 16-10-49 的屏幕截图.png"><br><img src="https://i.loli.net/2019/07/29/5d3eaa258db9847713.png" alt="2019-07-29 16-09-57 的屏幕截图.png"><br><img src="https://i.loli.net/2019/07/29/5d3eaa7dec8da36393.png" alt="2019-07-29 16-12-37 的屏幕截图.png"><br><img src="https://i.loli.net/2019/07/29/5d3eab6b3767473775.png" alt="2019-07-29 16-16-12 的屏幕截图.png"></p>
<h4 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h4><p>高级优化算法中会默认我们所传入的参数是会提供一些初始值的。<br>问题：如果对参数进行初始化？  </p>
<p><font color="red" size="5px">思想1：全部赋为0</font> ，在神经网络中并不适用   </p>
<p><font color="red" size="5px">思想2：随机初始化</font><br><img src="https://i.loli.net/2019/07/29/5d3eafe8d3d9240264.png" alt="2019-07-29 16-35-45 的屏幕截图.png"></p>
<h4 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h4><ol>
<li>选择神经网络结构：输入单元个数为单个样本输入X<sup>(i)</sup>的维数；输出单元的个数[1-10]都可以，但一般用向量且对应位为1其余为0表示i.e，[0,0,0,1,0,0]<sup>T</sup>；隐藏单元通常默认只有一层，但也可不止一层，这样每个隐藏层单元数要相同，通常等于特征数，或者是特征数的倍数个。</li>
<li>训练神经网络：随机初始化权重&theta;为接近0的数；实现前向传播算法得到h<sub>&theta;</sub>((x<sup>(i)</sup>))；计算代价函数；实现反向传播算法得到偏导数项；用梯度检查比较得出的偏导数项，确定偏差不大则屏蔽梯度检查部分；使用梯度下降或更高级的优化方法来最小化J(&theta;)并得到参数&theta;<br><img src="https://i.loli.net/2019/07/29/5d3eb41f9e37855213.png" alt="2019-07-29 16-53-29 的屏幕截图.png"><br><img src="https://i.loli.net/2019/07/29/5d3eb6788a0ca86336.png" alt="2019-07-29 17-03-44 的屏幕截图.png"></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sfz-lyq.cn/2019/07/29/神经网络参数的反向传播算法/" data-id="ck45j8t5w008idspvtlz7bm6o" class="article-share-link">分享</a>
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/机器学习/">机器学习</a></li></ul>

    </footer>

  </div>

  
    
  <nav class="article-nav">
    
      <a href="../../30/吴恩达机器学习第五次编程作用-正则线性回归和偏差-方差/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            吴恩达机器学习第五次编程作业-正则线性回归和偏差/方差
          
        </div>
      </a>
    
    
      <a href="../../28/南航第三周总结/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">2019.7.28 每周总结</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
    </div>
    <script src="../../../../js/jquery-2.0.3.min.js"></script>
<script src="../../../../js/lazyload.min.js"></script>
<script src="../../../../js/busuanzi-2.3.pure.min.js"></script>


  <script src="../../../../fancybox/jquery.fancybox.min.js"></script>



  <script src="../../../../js/search.js"></script>


<script src="../../../../js/technology.js"></script>

  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>