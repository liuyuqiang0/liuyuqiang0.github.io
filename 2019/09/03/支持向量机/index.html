<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="NO response">
  
  
    <meta name="description" content="what you will be,the world will be">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    支持向量机 |
    
    种花家</title>
  
    <link rel="shortcut icon" href="/images/rabbit.png">
  
  <link rel="stylesheet" href="../../../../css/style.css">
  <link rel="stylesheet" href="../../../../css/technology.css">
  
    <link rel="stylesheet" href="../../../../fancybox/jquery.fancybox.min.css">
  
  <script src="../../../../js/pace.min.js"></script>
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <section class="outer">
  <article id="post-支持向量机" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      支持向量机
    </h1>
  

      </header>
    

    
      <div class="article-meta">
        <a href class="article-date">
  <time datetime="2019-09-03T01:41:00.000Z" itemprop="datePublished">2019-09-03</time>
</a>
        
  <div class="article-category">
    <a class="article-category-link" href="../../../../categories/机器学习/">机器学习</a>
  </div>

      </div>
    

    <div class="article-entry" itemprop="articleBody">
      

      

      
        <h3 id="学习地址"><a href="#学习地址" class="headerlink" title="学习地址"></a><center><a href="https://study.163.com/course/courseLearn.htm?courseId=1004570029#/learn/video?lessonId=1052089362&amp;courseId=1004570029" target="_blank" rel="noopener">学习地址</a></center></h3><p>Support Vector Machine（SVM）</p>
<hr>
<h4 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h4><p>回顾逻辑回归的激活函数sigmoid<br><img src="https://i.loli.net/2019/09/03/Eh78yUXjPuGqWCA.png" alt="2019-09-03 09-50-57 的屏幕截图.png"><br>逻辑回归单个样本的代价函数如下，分别考虑当y=0和y=1时代价函数的变化情况  在这个基础上稍微变化一下，取z=&theta;<sup>T</sup>x的某一点，作两条直线如图，这个新的代价函数为cost<sub>_1</sub>(z)和cost<sub>_0</sub>(z)，这里下标0和1只是代表y=0或y=1。<br>有了这些定义就可构建支持向量机<br><img src="https://i.loli.net/2019/09/03/TZuB8W53eJD6v4I.png" alt="2019-09-03 09-59-39 的屏幕截图.png"></p>
<p>那么，用cost<sub>_1</sub>(z)和cost<sub>_0</sub>(z)分别代替-log(h<sub>&theta;</sub>(x<sup>(i)</sup>))和(-log(1-h<sub>&theta;</sub>(x<sup>(i)</sup>)))得到一个变体代价函数，对于1/m这只是个常数，完全不影响最优解，故可以省略。<br>将逻辑回归代价函数替换成A，正则化项替换成B，那么J(&theta;)=A+&lambda;B。&lambda;代表正则化项所占的权重，即&lambda;越大说明正则化项越重要。对于SVM，同样我们使用C来表示这个常数，我们需要优化的是CA+B，如果C很小那么C*A也很小，同样可以表示正则化项很重要,实际上C=1/&lambda;时和A+&lambda;B效果是一样的。<br>SVM中A则是使用cost替换了激活函数h<sub>&theta;</sub>(z)之后的A<sup>‘</sup>。那么就得到SVM需要优化的代价函数如下：<br><img src="https://i.loli.net/2019/09/03/K7wzSObad83Z2ut.png" alt="2019-09-03 10-28-31 的屏幕截图.png"></p>
<p>SVM并不会像逻辑回归输出概率，而是通过优化代价函数得到参数&theta;然后直接预测y=0或者y=1。<br><img src="https://i.loli.net/2019/09/03/ONkj7cviSRm5DfW.png" alt="2019-09-03 10-46-24 的屏幕截图.png"></p>
<h4 id="直观上对大间隔的理解"><a href="#直观上对大间隔的理解" class="headerlink" title="直观上对大间隔的理解"></a>直观上对大间隔的理解</h4><p>SVM有时也被成为大间距分类器。<br>实际上当&theta;<sup>T</sup>X&ge;0就可以正确把正负样本分开，但SVM并不仅仅将样本分开，而是考虑一个安全距离。下图已经给出关于z的代价函数。</p>
<p><img src="https://i.loli.net/2019/09/03/xGw2cj5Kh8kEsdy.png" alt="2019-09-03 11-12-46 的屏幕截图.png"><br>这个间距是指不同的分类效果离样本的距离，比如下图中黑色分隔线就是比较理想的一种情况。SVM会尽量把正负样本最大间距地隔开。<br><img src="https://i.loli.net/2019/09/03/K6a3roQE9xWkVNs.png" alt="2019-09-03 10-58-19 的屏幕截图.png"></p>
<h4 id="大间隔分类器的数学原理"><a href="#大间隔分类器的数学原理" class="headerlink" title="大间隔分类器的数学原理"></a>大间隔分类器的数学原理</h4><p>SVM是如何使得这个间距最大呢？<br>先看一个内积的例子：设u=[[u1,u2]]，v=[[v1,v2]]<br>那么向量u(两个坐标轴上投影长度分别为u1、u2)的长度||u||=&radic;<code>(u1*u1+u2*u2)</code>，这个长度就是u的范数<br>u和v的内积u<sup>T</sup>v如何计算？<br>定义p：v在u上的直角投影<br>那么u<sup>T</sup>v=p*||u||=u1v1+u2v2<br><img src="https://i.loli.net/2019/09/03/rwIdBiKDmWtz74k.png" alt="2019-09-03 11-58-55 的屏幕截图.png"></p>
<p>引入到SVM中，那么&theta;<sup>T</sup>x<sup>(i)</sup>=p<sup>(i)</sup>||&theta;||=&theta;<sub>1</sub>x<sub>1</sub><sup>(i)</sup>+&theta;<sub>2</sub>x<sub>2</sub><sup>(i)</sup>，p<sup>(i)</sup>是x<sup>(i)</sup>在向量&theta;上的投影<br><img src="https://i.loli.net/2019/09/03/hKy14bBMcukzGWd.png" alt="2019-09-03 18-44-28 的屏幕截图.png"></p>
<p>为什么SVM会选择间距最大的分类方式？<br>如下，如果想分出正负样本，选择左边的分类方式发现投影p<sup>(i)</sup>非常小，这就使得&amp;theta的范数必须非常大，而右边的分类方式则不存在这种问题。故决策边界离样本尽可能远。<br><img src="https://i.loli.net/2019/09/03/HyQJai1TNr2tgcu.png" alt="2019-09-03 18-55-54 的屏幕截图.png"></p>
<h4 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h4><p>用f<sub>_1</sub>代替特征x<sub>_1</sub>，f<sub>_2</sub>代替特征x<sub>_2</sub>，f<sub>_i</sub>代替特征x<sub>_j</sub>x<sub>_k</sub>。这样f的阶数可能是非常大的，如何更好地选择特征f？  </p>
<p>选择三个基点l<sup>(1)</sup>，l<sup>(2)</sup>，l<sup>(3)</sup>。<br>对于给定x：f<sub>_1</sub>=similarity(x,l<sup>(1)</sup>)=exp(-||x-l<sup>(1)</sup>||<sup>2</sup> / (2&sigma;<sup>2</sup>))<br>f<sub>_2</sub>…同理。  </p>
<p>这里相似度函数在数学上就是一个核函数，核函数有很多，这里使用的是高斯核函数，故也记作k(x,l<sup>(i)</sup>)<br><img src="https://i.loli.net/2019/09/04/sdSpa7bBYei6XQy.png" alt="2019-09-04 10-26-28 的屏幕截图.png"><br><img src="https://i.loli.net/2019/09/04/fn3WXegwvbVH18j.png" alt="2019-09-04 10-31-33 的屏幕截图.png"></p>
<p>如何选取基点l<sup>(i)</sup>呢？<br>实际上，基准点和训练样本点是一致的，即l<sup>(i)</sup>=x<sup>(i)</sup><br><img src="https://i.loli.net/2019/09/04/UVBmWdxTwf2a1R7.png" alt="2019-09-04 11-21-59 的屏幕截图.png"></p>
<p>优化目标整理：<br><img src="https://i.loli.net/2019/09/04/zvlxhSZVUHYLEbq.png" alt="2019-09-04 11-33-56 的屏幕截图.png"></p>
<p>如何选择参数C(=1/&lambda;)和&sigma;：<br><img src="https://i.loli.net/2019/09/04/LwWcnVtNFDvfjx3.png" alt="2019-09-04 11-39-18 的屏幕截图.png"></p>
<h4 id="使用SVM"><a href="#使用SVM" class="headerlink" title="使用SVM"></a>使用SVM</h4><p>有很多精准的计算库或者软件包进行求参优化问题，例如liblinear，libsvm等来求解参数&theta;，手动写的优化方法很难和专业库进行比优。  </p>
<p>但有几件事还是需要自己来具体实现</p>
<ul>
<li>参数C的选择</li>
<li>核函数(kernel)的选择(相似度函数similarity function)：例如，不带参数的核函数（线性核函数），预测y=1如果&theta;<sup>T</sup>x&ge;0；还可以选择带参数&sigma;的高斯核函数</li>
</ul>
<p><img src="https://i.loli.net/2019/09/04/QeTJbwYPcEjrXUS.png" alt="2019-09-04 15-58-00 的屏幕截图.png"></p>
<p>默塞尔定理，SVM数值计算包默认满足默塞尔定理以便优化方法正确计算<br>其他的核函数选择：</p>
<ul>
<li>多项式核函数：k(x,l)=(x<sup>T</sup>l+constant)<sup>2/3/4</sup>，constant=1/5/….</li>
<li>字符串核函数</li>
<li>卡方核函数</li>
<li>直方相交核函数 </li>
</ul>
<p>多分类器：<br><img src="https://i.loli.net/2019/09/04/mV8YSAvLOr65UhW.png" alt="2019-09-04 16-29-23 的屏幕截图.png"></p>
<p>选择逻辑回归还是SVM？</p>
<ul>
<li>特征数量n很大（n=10000），n&ge;m：选择逻辑回归或线形核函数</li>
<li>如果n很小（1-1000），m适中：选择高斯核函数</li>
<li>如果n很小，m很大：增加特征，使用逻辑回归或线形核函数</li>
</ul>
<p>神经网络可能都适用，但训练可能要更慢些。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sfz-lyq.cn/2019/09/03/支持向量机/" data-id="ck45pex77007asvpvaoxx2dk0" class="article-share-link">分享</a>
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/机器学习/">机器学习</a></li></ul>

    </footer>

  </div>

  
    
  <nav class="article-nav">
    
      <a href="../../05/吴恩达机器学习第六次编程作业/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            吴恩达机器学习第六次编程作业-支持向量机
          
        </div>
      </a>
    
    
      <a href="../../02/牛客练习赛50-部分题解/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">牛客练习赛50 部分题解</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
    </div>
    <script src="../../../../js/jquery-2.0.3.min.js"></script>
<script src="../../../../js/lazyload.min.js"></script>
<script src="../../../../js/busuanzi-2.3.pure.min.js"></script>


  <script src="../../../../fancybox/jquery.fancybox.min.js"></script>



  <script src="../../../../js/search.js"></script>


<script src="../../../../js/technology.js"></script>

  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>