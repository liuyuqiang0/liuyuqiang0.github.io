<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="NO response">
  
  
    <meta name="description" content="what you will be,the world will be">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    Python自然语言处理NLP(二) |
    
    种花家</title>
  
    <link rel="shortcut icon" href="/images/rabbit.png">
  
  <link rel="stylesheet" href="../../../../css/style.css">
  <link rel="stylesheet" href="../../../../css/technology.css">
  
    <link rel="stylesheet" href="../../../../fancybox/jquery.fancybox.min.css">
  
  <script src="../../../../js/pace.min.js"></script>
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <section class="outer">
  <article id="post-Python自然语言处理NLP-一" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python自然语言处理NLP(二)
    </h1>
  

      </header>
    

    
      <div class="article-meta">
        <a href class="article-date">
  <time datetime="2019-09-23T07:03:00.000Z" itemprop="datePublished">2019-09-23</time>
</a>
        
  <div class="article-category">
    <a class="article-category-link" href="../../../../categories/NLP/">NLP</a>
  </div>

      </div>
    

    <div class="article-entry" itemprop="articleBody">
      

      

      
        <h3 id="学习地址"><a href="#学习地址" class="headerlink" title="学习地址"></a><center><a href="https://www.bilibili.com/video/av29796449/?p=11" target="_blank" rel="noopener">学习地址</a></center></h3><h4 id="语料库"><a href="#语料库" class="headerlink" title="语料库"></a>语料库</h4><ul>
<li><p>古腾堡gutenberg</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import gutenberg</span><br><span class="line">emmma=gutenberg.words(&apos;austen-emma.txt&apos;) # j简爱</span><br><span class="line"># print(type(emmma),len(emmma)) # 192427</span><br><span class="line">for fileid in gutenberg.fileids(): # austen-emma.txt, austen-persuasion.txt, austen-sense.txt, ...</span><br><span class="line">    num_char=len(gutenberg.raw(fileid)) # sum every char</span><br><span class="line">    num_words=len(gutenberg.words(fileid)) # sum of word num</span><br><span class="line">    num_sents=len(gutenberg.sents(fileid)) # sum of sentence num</span><br><span class="line">    num_vocab=len(set([w.lower() for w in gutenberg.words(fileid)]))</span><br><span class="line">    print(fileid,&apos;:&apos;,num_char//num_words,num_words//num_sents,num_words//num_vocab)</span><br></pre></td></tr></table></figure>
</li>
<li><p>网络聊天webtext</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import webtext </span><br><span class="line">for fileid in webtext.fileids():</span><br><span class="line">    print(fileid,&apos;: &apos;,webtext.raw(fileid)[:50]) # 每种类型的网络用语内容前50个单词</span><br></pre></td></tr></table></figure>
</li>
<li><p>即时聊天语料库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import nps_chat</span><br><span class="line">for fileid in nps_chat.fileids():</span><br><span class="line">    print(fileid) # # 10-19-20s_706posts.xml, 10-19-30s_705posts.xml, 10-19-40s_686posts.xml</span><br><span class="line">chatroom=nps_chat.posts(&apos;10-19-20s_706posts.xml&apos;)</span><br><span class="line">print(type(chatroom),len(chatroom))</span><br><span class="line">print(chatroom[123]) # [&apos;i&apos;, &apos;do&apos;, &quot;n&apos;t&quot;, &apos;want&apos;, &apos;hot&apos;, &apos;pics&apos;, &apos;of&apos;, &apos;a&apos;, &apos;female&apos;, &apos;,&apos;, &apos;I&apos;, &apos;can&apos;, &apos;look&apos;, &apos;in&apos;, &apos;a&apos;, &apos;mirror&apos;, &apos;.&apos;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>布朗语料库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import brown</span><br><span class="line">for fileid in brown.fileids(): # ca01, ca02, ca03, ca04, ...</span><br><span class="line">    print(fileid)</span><br><span class="line">for x in brown.categories(): # adventure, belles_lettres, editorial, fiction, government, hobbies, humor, ...</span><br><span class="line">    print(x)</span><br><span class="line">news_text1=brown.words(categories=&apos;news&apos;)</span><br><span class="line">print(news_text1) # [&apos;The&apos;, &apos;Fulton&apos;, &apos;County&apos;, &apos;Grand&apos;, &apos;Jury&apos;, &apos;said&apos;, ...]</span><br><span class="line">news_text2=brown.words(fileids=[&apos;cg22&apos;])</span><br><span class="line">print(news_text2) # [&apos;Does&apos;, &apos;our&apos;, &apos;society&apos;, &apos;have&apos;, &apos;a&apos;, &apos;runaway&apos;, &apos;,&apos;, ...]</span><br><span class="line">news_text3=brown.sents(categories=[&apos;news&apos;,&apos;editorial&apos;,&apos;reviews&apos;])</span><br><span class="line">print(news_text3)</span><br></pre></td></tr></table></figure>
</li>
<li><p>路透社语料库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import reuters</span><br><span class="line">print(len(reuters.fileids())) # 10788</span><br><span class="line">print(len(reuters.categories())) # 90</span><br></pre></td></tr></table></figure>
</li>
<li><p>就职演讲语料</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import inaugural</span><br><span class="line"></span><br><span class="line">cfd=nltk.ConditionalFreqDist(</span><br><span class="line">    (target,fileid[:4])</span><br><span class="line">    for fileid in inaugural.fileids()</span><br><span class="line">    for w in inaugural.words(fileid)</span><br><span class="line">    for target in [&apos;america&apos;,&apos;citizen&apos;]</span><br><span class="line">    if w.lower().startswith(target)</span><br><span class="line">)</span><br><span class="line">cfd.plot() # Construct a new empty conditional frequency distribution</span><br></pre></td></tr></table></figure>
<p><img src="https://www.privacypic.com/images/2019/09/23/Figure_39b8d1601601d5d69b.png" alt="Figure_39b8d1601601d5d69b.png"></p>
<h4 id="条件频率分布"><a href="#条件频率分布" class="headerlink" title="条件频率分布"></a>条件频率分布</h4><p>nltk有两种方法可以生成频率图，一种是上图所示代码，另外一种用表格形式生成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import udhr</span><br><span class="line"></span><br><span class="line">cfd=nltk.ConditionalFreqDist(</span><br><span class="line">    (lang,len(word))</span><br><span class="line">    for lang in [&apos;English&apos;,&apos;German_Deutsch&apos;]</span><br><span class="line">    for word in udhr.words(lang+&apos;-Latin1&apos;)</span><br><span class="line">)</span><br><span class="line">cfd.tabulate(conditions=[&apos;English&apos;,&apos;German_Deutsch&apos;],samples=np.arange(10),cumulative=False)</span><br><span class="line"></span><br><span class="line">- - - - - - - - - - - - -</span><br><span class="line">                 0   1   2   3   4   5   6   7   8   9 </span><br><span class="line">       English   0 185 340 358 114 169 117 157 118  80 </span><br><span class="line">German_Deutsch   0 171  92 351 103 177 119  97 103  62</span><br></pre></td></tr></table></figure></p>
<h4 id="词典"><a href="#词典" class="headerlink" title="词典"></a>词典</h4><ul>
<li><p>停用词：高频词汇但是没有什么实际意义，如’a’,’an’,’the’ …，在实际应用中可以将这些高频词汇过滤掉，剩下一些关键词更有研究意义。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def content_fraction(text): # 提取关键词</span><br><span class="line">    stopwords = stopwords.words(&apos;english&apos;)</span><br><span class="line">    content=[w for w in text if w.lower() not in stopwords] # 过滤停用词</span><br><span class="line">    return content</span><br></pre></td></tr></table></figure>
</li>
<li><p>发音词典</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import  cmudict</span><br><span class="line"></span><br><span class="line">entries=cmudict.entries()</span><br><span class="line">#print(len(entries)) # 133737</span><br><span class="line">for entry in entries[39943:39951]:</span><br><span class="line">    print(entry)</span><br><span class="line">- - - - - - - - - - - - - - -</span><br><span class="line">(&apos;explorer&apos;, [&apos;IH0&apos;, &apos;K&apos;, &apos;S&apos;, &apos;P&apos;, &apos;L&apos;, &apos;AO1&apos;, &apos;R&apos;, &apos;ER0&apos;])</span><br><span class="line">(&apos;explorers&apos;, [&apos;IH0&apos;, &apos;K&apos;, &apos;S&apos;, &apos;P&apos;, &apos;L&apos;, &apos;AO1&apos;, &apos;R&apos;, &apos;ER0&apos;, &apos;Z&apos;])</span><br><span class="line">(&apos;explores&apos;, [&apos;IH0&apos;, &apos;K&apos;, &apos;S&apos;, &apos;P&apos;, &apos;L&apos;, &apos;AO1&apos;, &apos;R&apos;, &apos;Z&apos;])</span><br><span class="line">(&apos;exploring&apos;, [&apos;IH0&apos;, &apos;K&apos;, &apos;S&apos;, &apos;P&apos;, &apos;L&apos;, &apos;AO1&apos;, &apos;R&apos;, &apos;IH0&apos;, &apos;NG&apos;])</span><br><span class="line">(&apos;explosion&apos;, [&apos;IH0&apos;, &apos;K&apos;, &apos;S&apos;, &apos;P&apos;, &apos;L&apos;, &apos;OW1&apos;, &apos;ZH&apos;, &apos;AH0&apos;, &apos;N&apos;])</span><br><span class="line">(&apos;explosions&apos;, [&apos;IH0&apos;, &apos;K&apos;, &apos;S&apos;, &apos;P&apos;, &apos;L&apos;, &apos;OW1&apos;, &apos;ZH&apos;, &apos;AH0&apos;, &apos;N&apos;, &apos;Z&apos;])</span><br><span class="line">(&apos;explosive&apos;, [&apos;IH0&apos;, &apos;K&apos;, &apos;S&apos;, &apos;P&apos;, &apos;L&apos;, &apos;OW1&apos;, &apos;S&apos;, &apos;IH0&apos;, &apos;V&apos;])</span><br><span class="line">(&apos;explosively&apos;, [&apos;EH2&apos;, &apos;K&apos;, &apos;S&apos;, &apos;P&apos;, &apos;L&apos;, &apos;OW1&apos;, &apos;S&apos;, &apos;IH0&apos;, &apos;V&apos;, &apos;L&apos;, &apos;IY0&apos;])</span><br></pre></td></tr></table></figure>
</li>
<li><p>词汇工具<code>from nltk.corpus import toolbox</code></p>
</li>
</ul>
<h4 id="同义词"><a href="#同义词" class="headerlink" title="同义词"></a>同义词</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from nltk.corpus import wordnet as wn</span><br><span class="line">similar=wn.synsets(&apos;sweet&apos;)</span><br><span class="line">print(similar) # 查看所属同义词集</span><br><span class="line">print(wn.synset(&apos;sweet.n.01&apos;).definition()) # 查看这种词集的定义</span><br><span class="line">print(wn.synset(&apos;car.n.01&apos;).examples()) # 这种定义下的一个例句</span><br><span class="line">print(wn.synset(&apos;car.n.01&apos;).lemmas()) # 查看同义词集词条</span><br><span class="line">print(wn.lemma(&apos;car.n.01.automobile&apos;).synset()) # 查找所属同义词集</span><br><span class="line"></span><br><span class="line">- - - - - - - - - - - - - - - - - - </span><br><span class="line">[Synset(&apos;sweet.n.01&apos;), Synset(&apos;dessert.n.01&apos;), Synset(&apos;sweet.n.03&apos;), Synset(&apos;sweet.n.04&apos;), Synset(&apos;sweetness.n.02&apos;), Synset(&apos;sweet.a.01&apos;), Synset(&apos;angelic.s.03&apos;), Synset(&apos;dulcet.s.02&apos;), Synset(&apos;sweet.s.04&apos;), Synset(&apos;gratifying.s.01&apos;), Synset(&apos;odoriferous.s.03&apos;), Synset(&apos;sweet.a.07&apos;), Synset(&apos;fresh.a.06&apos;), Synset(&apos;fresh.s.09&apos;), Synset(&apos;sugared.s.01&apos;), Synset(&apos;sweetly.r.01&apos;)]</span><br><span class="line">English phonetician; one of the founders of modern phonetics (1845-1912)</span><br><span class="line">[&apos;he needs a car to get to work&apos;]</span><br><span class="line">[Lemma(&apos;car.n.01.car&apos;), Lemma(&apos;car.n.01.auto&apos;), Lemma(&apos;car.n.01.automobile&apos;), Lemma(&apos;car.n.01.machine&apos;), Lemma(&apos;car.n.01.motorcar&apos;)]</span><br><span class="line">Synset(&apos;car.n.01&apos;)</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://sfz-lyq.cn/2019/09/23/Python自然语言处理NLP-一/" data-id="ck45j8t32003wdspv7w4nkmws" class="article-share-link">分享</a>
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/Python/">Python</a></li></ul>

    </footer>

  </div>

  
    
  <nav class="article-nav">
    
      <a href="../../24/Python自然语言处理NLP-三/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Python自然语言处理NLP(三)
          
        </div>
      </a>
    
    
      <a href="../../22/自然语言处理NLP-一/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Python自然语言处理NLP(一)</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
    </div>
    <script src="../../../../js/jquery-2.0.3.min.js"></script>
<script src="../../../../js/lazyload.min.js"></script>
<script src="../../../../js/busuanzi-2.3.pure.min.js"></script>


  <script src="../../../../fancybox/jquery.fancybox.min.js"></script>



  <script src="../../../../js/search.js"></script>


<script src="../../../../js/technology.js"></script>

  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>